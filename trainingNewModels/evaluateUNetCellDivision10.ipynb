{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgitb import reset\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import skimage as sm\n",
    "import skimage.io\n",
    "from matplotlib import pyplot as plt\n",
    "import tifffile\n",
    "import timm\n",
    "import os\n",
    "from fastai.vision.all import *\n",
    "from skimage.feature import blob, blob_dog, blob_log, blob_doh\n",
    "from os.path import exists\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_HEIGHT = 512\n",
    "IMAGE_WIDTH = 512\n",
    "PIN_MEMORY = True\n",
    "\n",
    "# util\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Creating directory. \" + directory)\n",
    "\n",
    "\n",
    "class VidDataset(Dataset):\n",
    "    def __init__(self, filename, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        filenames = os.listdir(image_dir)\n",
    "        filenames.sort()\n",
    "        if \".DS_Store\" in filenames:\n",
    "            filenames.remove(\".DS_Store\")\n",
    "        if f\"focus{filename}.tif\" in filenames:\n",
    "            filenames.remove(f\"focus{filename}.tif\")\n",
    "        if \".ipynb_checkpoints\" in filenames:\n",
    "            filenames.remove(\".ipynb_checkpoints\")\n",
    "        self.images = filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.image_dir, self.images[index])\n",
    "        image = sm.io.imread(img_path).astype(np.float32)\n",
    "        images = torch.tensor(image/256).float()\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image[0], image0=image[1], image1=image[2], image2=image[3],\n",
    "                                         image3=image[4], image4=image[5], image5=image[6], image6=image[7],\n",
    "                                         image7=image[8], image8=image[9])\n",
    "            images[0] = transformed[\"image\"]\n",
    "            images[1] = transformed[\"image0\"]\n",
    "            images[2] = transformed[\"image1\"]\n",
    "            images[3] = transformed[\"image2\"]\n",
    "            images[4] = transformed[\"image3\"]\n",
    "            images[5] = transformed[\"image4\"]\n",
    "            images[6] = transformed[\"image5\"]\n",
    "            images[7] = transformed[\"image6\"]\n",
    "            images[8] = transformed[\"image7\"]\n",
    "            images[9] = transformed[\"image8\"]\n",
    "            \n",
    "        pred_name = self.images[index].replace(\".tif\", \"\")\n",
    "\n",
    "        return images, pred_name\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "\n",
    "def get_loaders(\n",
    "    filename_dir,\n",
    "    batch_size,\n",
    "    filename_transform,\n",
    "    filename,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "):\n",
    "    filename_ds = VidDataset(\n",
    "        filename,\n",
    "        image_dir=filename_dir,\n",
    "        transform=filename_transform,\n",
    "    )\n",
    "\n",
    "    filename_loader = DataLoader(\n",
    "        filename_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    return filename_loader\n",
    "\n",
    "\n",
    "def make_predictions(loader, model, filename, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    loop = tqdm(loader)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, pred_name) in enumerate(loop):\n",
    "            x = x.to(device)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            preds = np.asarray(preds*255, \"uint8\")\n",
    "            for i in range(preds.shape[0]):\n",
    "                tifffile.imwrite(\n",
    "                    f\"dat_midpoint/{filename}/pred_{pred_name[i]}.tif\", preds[i])\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "def make_predictions_Orientation(loader, model, filename, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    loop = tqdm(loader)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, pred_name) in enumerate(loop):\n",
    "            x = x.to(device)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            preds = np.asarray(preds*255, \"uint8\")\n",
    "            for i in range(preds.shape[0]):\n",
    "                tifffile.imwrite(\n",
    "                    f\"dat_midpoint/{filename}/Masks/{pred_name[i]}.tif\", preds[i])\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "    \n",
    "def sortDL(df, t, x, y):\n",
    "\n",
    "    a = df[df[\"T\"] == t - 2]\n",
    "    b = df[df[\"T\"] == t - 1]\n",
    "    c = df[df[\"T\"] == t + 1]\n",
    "    d = df[df[\"T\"] == t + 2]\n",
    "\n",
    "    df = pd.concat([a, b, c, d])\n",
    "\n",
    "    xMax = x + 13\n",
    "    xMin = x - 13\n",
    "    yMax = y + 13\n",
    "    yMin = y - 13\n",
    "    if xMax > 511:\n",
    "        xMax = 511\n",
    "    if yMax > 511:\n",
    "        yMax = 511\n",
    "    if xMin < 0:\n",
    "        xMin = 0\n",
    "    if yMin < 0:\n",
    "        yMin = 0\n",
    "\n",
    "    dfxmin = df[df[\"X\"] >= xMin]\n",
    "    dfx = dfxmin[dfxmin[\"X\"] < xMax]\n",
    "\n",
    "    dfymin = dfx[dfx[\"Y\"] >= yMin]\n",
    "    df = dfymin[dfymin[\"Y\"] < yMax]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def intensity(vid, ti, xi, yi):\n",
    "\n",
    "    [T, X, Y] = vid.shape\n",
    "\n",
    "    vidBoundary = np.zeros([T, 552, 552])\n",
    "\n",
    "    for x in range(X):\n",
    "        for y in range(Y):\n",
    "            vidBoundary[:, 20 + x, 20 + y] = vid[:, x, y]\n",
    "\n",
    "    rr, cc = sm.draw.disk([yi + 20, xi + 20], 9)\n",
    "    div = vidBoundary[ti][rr, cc]\n",
    "    div = div[div > 0]\n",
    "\n",
    "    mu = np.mean(div)\n",
    "\n",
    "    return mu\n",
    "    \n",
    "    \n",
    "def maskOrientation(mask):\n",
    "    S = np.zeros([2, 2])\n",
    "    X, Y = mask.shape\n",
    "    x = np.zeros([X, Y])\n",
    "    y = np.zeros([X, Y])\n",
    "    x += np.arange(X)\n",
    "    y += (Y - 1 - np.arange(Y)).reshape(Y, 1)\n",
    "    A = np.sum(mask)\n",
    "    Cx = np.sum(x * mask) / A\n",
    "    Cy = np.sum(y * mask) / A\n",
    "    xx = (x - Cx) ** 2\n",
    "    yy = (y - Cy) ** 2\n",
    "    xy = (x - Cx) * (y - Cy)\n",
    "    S[0, 0] = -np.sum(yy * mask) / A ** 2\n",
    "    S[1, 0] = S[0, 1] = np.sum(xy * mask) / A ** 2\n",
    "    S[1, 1] = -np.sum(xx * mask) / A ** 2\n",
    "    TrS = S[0, 0] + S[1, 1]\n",
    "    I = np.zeros(shape=(2, 2))\n",
    "    I[0, 0] = 1\n",
    "    I[1, 1] = 1\n",
    "    q = S - TrS * I / 2\n",
    "    theta = np.arctan2(q[0, 1], q[0, 0]) / 2\n",
    "\n",
    "    return theta * 180 / np.pi\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    target10 = {'image0': 'image', 'image1': 'image', 'image2': 'image', 'image3': 'image',\n",
    "                'image4': 'image', 'image5': 'image', 'image6': 'image', 'image7': 'image',\n",
    "                'image8': 'image', 'image9': 'image'}\n",
    "    filename_transform = A.Compose(\n",
    "        [\n",
    "            A.Normalize(\n",
    "                mean=0,\n",
    "                std=1,\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        additional_targets=target10,\n",
    "    )\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    filenames = os.listdir(cwd + \"/dat_pred\")\n",
    "    if \".DS_Store\" in filenames:\n",
    "        filenames.remove(\".DS_Store\")\n",
    "    if \".ipynb_checkpoints\" in filenames:\n",
    "        filenames.remove(\".ipynb_checkpoints\")\n",
    "    filenames.sort()\n",
    "    \n",
    "    # ---------- Find Divisions ----------\n",
    "\n",
    "    resnet = timm.create_model(\"resnet34\", pretrained=True)\n",
    "    resnet.conv1 = nn.Conv2d(10, 64, kernel_size=(\n",
    "        7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "    m = resnet\n",
    "    m = nn.Sequential(*list(m.children())[:-2])\n",
    "    model = DynamicUnet(m, 1, (512, 512), norm_type=None).to(DEVICE)\n",
    "#     x = cast(torch.randn(2, 10, 512, 512), TensorImage)\n",
    "#     y = model(x)\n",
    "    load_checkpoint(torch.load(\"models/UNetCellDivision10.pth.tar\"), model)\n",
    "\n",
    "\n",
    "    label=0\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        path_to_file = f\"dat_midpoint/{filename}/dfDivisions{filename}.pkl\"\n",
    "        if False == exists(path_to_file):\n",
    "            print(label)\n",
    "            createFolder(f\"dat_midpoint/{filename}\")\n",
    "            FILENAME_IMG_DIR = f\"dat_pred/{filename}/\"\n",
    "            filename_loader = get_loaders(\n",
    "                FILENAME_IMG_DIR,\n",
    "                BATCH_SIZE,\n",
    "                filename_transform,  # train_transform\n",
    "                filename,\n",
    "                NUM_WORKERS,\n",
    "                PIN_MEMORY,\n",
    "            )\n",
    "\n",
    "            focus = sm.io.imread(f\"dat_pred/{filename}/focus{filename}.tif\").astype(int)\n",
    "            T = focus.shape[0]-4\n",
    "\n",
    "            make_predictions(filename_loader, model, filename)\n",
    "\n",
    "            vid = np.zeros([T, 512, 512])\n",
    "\n",
    "            img = np.zeros([552, 552])\n",
    "            vid[0] = sm.io.imread(f\"dat_midpoint/{filename}/pred_{filename}_{0}.tif\").astype(int)\n",
    "            img[20:532, 20:532] = vid[0]\n",
    "            blobs = blob_log(img, min_sigma=10, max_sigma=25, num_sigma=25, threshold=30)\n",
    "            blobs_logs = np.concatenate((blobs, np.zeros([len(blobs), 1])), axis=1)\n",
    "\n",
    "            for t in range(1, T):\n",
    "                img = np.zeros([552, 552])        \n",
    "                vid[t] = sm.io.imread(f\"dat_midpoint/{filename}/pred_{filename}_{t}.tif\").astype(int)\n",
    "                img[20:532, 20:532] = vid[t]\n",
    "                blobs = blob_log(img, min_sigma=10, max_sigma=25, num_sigma=25, threshold=30)\n",
    "                blobs_log = np.concatenate((blobs, np.zeros([len(blobs), 1]) + t), axis=1)\n",
    "                blobs_logs = np.concatenate((blobs_logs, blobs_log))\n",
    "\n",
    "\n",
    "            _df = []\n",
    "            for blob in blobs_logs:\n",
    "                y, x, r, t = blob\n",
    "                mu = intensity(vid, int(t), int(x - 20), int(y - 20))\n",
    "\n",
    "                _df.append(\n",
    "                    {\n",
    "                        \"Label\": label,\n",
    "                        \"T\": int(t + 1),\n",
    "                        \"X\": int(x - 20),\n",
    "                        \"Y\": 532 - int(y),  # map coords without boundary\n",
    "                        \"Intensity\": mu,\n",
    "                    }\n",
    "                )\n",
    "                label += 1\n",
    "\n",
    "            df = pd.DataFrame(_df)\n",
    "            df.to_pickle(f\"dat_midpoint/{filename}/_dfDivisions{filename}.pkl\")\n",
    "            dfRemove = pd.read_pickle(f\"dat_midpoint/{filename}/_dfDivisions{filename}.pkl\")\n",
    "\n",
    "            for i in range(len(df)):\n",
    "                ti, xi, yi = df[\"T\"].iloc[i], df[\"X\"].iloc[i], df[\"Y\"].iloc[i]\n",
    "                labeli = df[\"Label\"].iloc[i]\n",
    "                dfmulti = sortDL(df, ti, xi, yi)\n",
    "                dfmulti = dfmulti.drop_duplicates(subset=[\"T\", \"X\", \"Y\"])\n",
    "\n",
    "                if len(dfmulti) > 0:\n",
    "                    mui = df[\"Intensity\"].iloc[i]\n",
    "                    for j in range(len(dfmulti)):\n",
    "                        tj, xj, yj = (\n",
    "                            dfmulti[\"T\"].iloc[j],\n",
    "                            dfmulti[\"X\"].iloc[j],\n",
    "                            dfmulti[\"Y\"].iloc[j],\n",
    "                        )\n",
    "                        labelj = dfmulti[\"Label\"].iloc[j]\n",
    "                        muj = dfmulti[\"Intensity\"].iloc[j]\n",
    "\n",
    "                        if mui < muj:\n",
    "                            indexNames = dfRemove[dfRemove[\"Label\"] == labeli].index\n",
    "                            dfRemove.drop(indexNames, inplace=True)\n",
    "                        else:\n",
    "                            indexNames = dfRemove[dfRemove[\"Label\"] == labelj].index\n",
    "                            dfRemove.drop(indexNames, inplace=True)\n",
    "\n",
    "            dfDivisions = dfRemove.drop_duplicates(subset=[\"T\", \"X\", \"Y\"])\n",
    "            dfDivisions.to_pickle(f\"dat_midpoint/{filename}/dfDivisions{filename}.pkl\")\n",
    "            os.remove(f\"dat_midpoint/{filename}/_dfDivisions{filename}.pkl\")\n",
    "\n",
    "            createFolder(f\"dat_midpoint/{filename}/Divisions\")\n",
    "\n",
    "            for k in range(len(dfDivisions)):\n",
    "                label = int(dfDivisions[\"Label\"].iloc[k])\n",
    "                t = int(dfDivisions[\"T\"].iloc[k])\n",
    "                x = int(dfDivisions[\"X\"].iloc[k])\n",
    "                y = int(512 - dfDivisions[\"Y\"].iloc[k])\n",
    "\n",
    "                xMax = int(x + 30)\n",
    "                xMin = int(x - 30)\n",
    "                yMax = int(y + 30)\n",
    "                yMin = int(y - 30)\n",
    "                if xMax > 512:\n",
    "                    xMaxCrop = 60 - (xMax - 512)\n",
    "                    xMax = 512\n",
    "                else:\n",
    "                    xMaxCrop = 60\n",
    "                if xMin < 0:\n",
    "                    xMinCrop = -xMin\n",
    "                    xMin = 0\n",
    "                else:\n",
    "                    xMinCrop = 0\n",
    "                if yMax > 512:\n",
    "                    yMaxCrop = 60 - (yMax - 512)\n",
    "                    yMax = 512\n",
    "                else:\n",
    "                    yMaxCrop = 60\n",
    "                if yMin < 0:\n",
    "                    yMinCrop = -yMin\n",
    "                    yMin = 0\n",
    "                else:\n",
    "                    yMinCrop = 0\n",
    "\n",
    "                vid = np.zeros([10, 120, 120])\n",
    "                for i in range(5):\n",
    "                    image = np.zeros([60, 60])\n",
    "\n",
    "                    image[yMinCrop:yMaxCrop, xMinCrop:xMaxCrop] = focus[t - 1 + i, yMin:yMax, xMin:xMax, 1]\n",
    "\n",
    "                    image = np.asarray(image, \"uint8\")\n",
    "                    tifffile.imwrite(\"dat_midpoint/images.tif\", image)\n",
    "\n",
    "                    division = Image.open(\"dat_midpoint/images.tif\")\n",
    "\n",
    "                    division = division.resize((120, 120))\n",
    "                    vid[2 * i] = division\n",
    "\n",
    "                    image = np.zeros([60, 60])\n",
    "\n",
    "                    image[yMinCrop:yMaxCrop, xMinCrop:xMaxCrop] = focus[t - 1 + i, yMin:yMax, xMin:xMax, 0]\n",
    "\n",
    "                    image = np.asarray(image, \"uint8\")\n",
    "                    tifffile.imwrite(\"dat_midpoint/images.tif\", image)\n",
    "\n",
    "                    division = Image.open(\"dat_midpoint/images.tif\")\n",
    "\n",
    "                    division = division.resize((120, 120))\n",
    "                    vid[2 * i + 1] = division\n",
    "\n",
    "                vid = np.asarray(vid, \"uint8\")\n",
    "                tifffile.imwrite(\n",
    "                    f\"dat_midpoint/{filename}/Divisions/division{label}.tif\", vid\n",
    "                )\n",
    "\n",
    "    # ---------- Find Orientation ----------\n",
    "            \n",
    "    resnet = timm.create_model(\"resnet34\", pretrained=True)\n",
    "    resnet.conv1 = nn.Conv2d(10, 64, kernel_size=(\n",
    "        7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "    m = resnet\n",
    "    m = nn.Sequential(*list(m.children())[:-2])\n",
    "    model = DynamicUnet(m, 1, (120, 120), norm_type=None).to(DEVICE)\n",
    "#     x = cast(torch.randn(2, 10, 512, 512), TensorImage)\n",
    "#     y = model(x)\n",
    "    load_checkpoint(torch.load(\"models/UNetOrientation.pth.tar\"), model)\n",
    "\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        createFolder(f\"dat_midpoint/{filename}/Masks\")\n",
    "        \n",
    "        filename_loader = get_loaders(\n",
    "            f\"dat_midpoint/{filename}/Divisions/\",\n",
    "            BATCH_SIZE*8,\n",
    "            filename_transform, \n",
    "            filename,\n",
    "            NUM_WORKERS,\n",
    "            PIN_MEMORY,\n",
    "        )\n",
    "        make_predictions_Orientation(filename_loader, model, filename)\n",
    "    \n",
    "    for filename in filenames:\n",
    "        _df = []\n",
    "        dfDivisions = pd.read_pickle(f\"dat_midpoint/{filename}/dfDivisions{filename}.pkl\")\n",
    "        for k in range(len(dfDivisions)):\n",
    "            label = int(dfDivisions[\"Label\"].iloc[k])\n",
    "            mask = sm.io.imread(f\"dat_midpoint/{filename}/Masks/division{label}.tif\").astype(int)[0]\n",
    "            ori_mask = maskOrientation(mask)\n",
    "            \n",
    "            _df.append(\n",
    "                {\n",
    "                    \"Label\": label,\n",
    "                    \"T\": dfDivisions[\"T\"].iloc[k],\n",
    "                    \"X\": dfDivisions[\"X\"].iloc[k],\n",
    "                    \"Y\": dfDivisions[\"Y\"].iloc[k],  \n",
    "                    \"Orientation\": ori_mask,\n",
    "                }\n",
    "            )\n",
    "            print(label, int(ori_mask), dfDivisions[\"T\"].iloc[k], \n",
    "                  dfDivisions[\"X\"].iloc[k], dfDivisions[\"Y\"].iloc[k])\n",
    "            \n",
    "        df = pd.DataFrame(_df)\n",
    "        df.to_pickle(f\"dat_output/dfDivision{filename}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "Unwound18h13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "Unwound18h13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:55<00:00, 18.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 37 1 264 401\n",
      "1 -64 1 300 450\n",
      "2 14 1 91 256\n",
      "4 82 2 232 70\n",
      "5 -53 2 351 391\n",
      "6 -53 3 350 361\n",
      "7 -69 3 470 188\n",
      "8 49 3 504 501\n",
      "9 -62 3 419 462\n",
      "10 25 3 402 364\n",
      "11 45 4 8 56\n",
      "12 -69 5 437 197\n",
      "13 31 6 322 282\n",
      "14 -29 6 150 369\n",
      "15 -27 7 93 400\n",
      "16 -83 7 200 370\n",
      "17 80 7 277 389\n",
      "18 -50 7 262 430\n",
      "19 -70 7 382 317\n",
      "20 58 8 30 353\n",
      "21 47 8 456 253\n",
      "22 65 9 84 477\n",
      "23 62 10 282 505\n",
      "24 -87 10 7 414\n",
      "25 -77 10 192 447\n",
      "26 6 11 179 346\n",
      "27 -28 11 46 459\n",
      "28 -52 12 223 267\n",
      "29 -83 12 280 437\n",
      "30 51 12 50 361\n",
      "31 3 12 37 391\n",
      "33 44 13 86 427\n",
      "34 41 13 267 315\n",
      "35 17 13 135 259\n",
      "36 -3 14 27 411\n",
      "37 12 14 69 63\n",
      "38 -9 14 176 253\n",
      "39 70 15 227 19\n",
      "40 -54 15 307 373\n",
      "41 -47 16 76 22\n",
      "42 -63 16 104 6\n",
      "43 -54 17 79 324\n",
      "44 -59 18 45 345\n",
      "45 -51 19 9 15\n",
      "46 70 19 502 33\n",
      "47 53 23 23 219\n",
      "48 -49 24 116 26\n",
      "49 -83 25 493 314\n",
      "50 -61 25 496 486\n",
      "51 -63 26 5 135\n",
      "52 76 28 135 145\n",
      "53 22 29 337 104\n",
      "54 52 29 116 57\n",
      "55 84 31 128 37\n",
      "56 -31 33 64 414\n",
      "57 -79 33 490 322\n",
      "58 -80 35 425 80\n",
      "59 34 35 194 141\n",
      "60 -76 36 15 142\n",
      "61 -81 37 160 296\n",
      "62 -49 38 463 243\n",
      "63 -66 39 425 245\n",
      "64 -60 39 46 403\n",
      "65 14 39 174 106\n",
      "66 -51 39 96 165\n",
      "67 51 40 95 93\n",
      "68 -79 40 175 58\n",
      "69 -16 40 149 78\n",
      "71 30 41 109 25\n",
      "72 34 42 92 119\n",
      "73 -77 42 473 105\n",
      "74 -87 43 133 41\n",
      "75 79 43 284 168\n",
      "76 -36 44 233 296\n",
      "77 -5 44 63 22\n",
      "78 13 46 123 380\n",
      "79 -51 46 137 123\n",
      "80 40 47 174 43\n",
      "81 -45 48 19 382\n",
      "82 59 49 118 101\n",
      "83 19 49 440 131\n",
      "84 -47 50 102 20\n",
      "85 66 50 195 196\n",
      "86 -82 50 490 307\n",
      "87 30 52 327 253\n",
      "88 -59 53 406 93\n",
      "89 58 53 490 89\n",
      "90 -24 53 331 130\n",
      "91 49 53 89 362\n",
      "92 -65 55 136 39\n",
      "94 37 56 19 127\n",
      "95 -23 56 41 76\n",
      "96 25 57 89 142\n",
      "97 -39 58 444 238\n",
      "98 29 58 359 119\n",
      "99 40 59 471 501\n",
      "100 -37 59 448 263\n",
      "101 -43 59 68 23\n",
      "102 -26 60 328 249\n",
      "103 -58 60 97 79\n",
      "104 -78 60 455 322\n",
      "105 44 60 57 45\n",
      "106 -43 60 361 383\n",
      "107 -61 60 226 176\n",
      "108 8 60 498 308\n",
      "109 -67 61 15 172\n",
      "110 -80 61 318 319\n",
      "111 22 61 176 252\n",
      "112 73 61 188 177\n",
      "113 50 61 312 166\n",
      "114 61 61 479 180\n",
      "115 -33 62 468 289\n",
      "116 83 62 98 154\n",
      "117 -37 62 346 219\n",
      "119 -45 63 8 91\n",
      "120 9 63 401 121\n",
      "121 48 63 397 159\n",
      "122 -63 64 436 291\n",
      "123 -70 64 5 230\n",
      "124 -37 66 22 151\n",
      "125 26 66 128 197\n",
      "126 17 66 223 199\n",
      "127 81 68 361 207\n",
      "128 11 70 6 296\n",
      "129 -83 70 12 172\n",
      "130 38 71 77 267\n",
      "131 68 71 120 184\n",
      "132 63 72 471 129\n",
      "133 52 72 161 190\n",
      "134 -63 73 357 291\n",
      "135 -68 73 58 131\n",
      "136 38 73 13 203\n",
      "137 33 73 144 233\n",
      "138 -61 73 135 195\n",
      "139 61 73 191 155\n",
      "140 26 73 503 336\n",
      "141 45 73 193 222\n",
      "142 55 73 264 131\n",
      "143 -49 74 452 287\n",
      "144 53 75 406 223\n",
      "145 11 75 315 114\n",
      "146 -12 75 481 286\n",
      "147 -80 75 475 108\n",
      "148 24 76 280 236\n",
      "149 -74 76 375 250\n",
      "150 78 76 220 235\n",
      "151 43 76 51 180\n",
      "153 58 77 77 182\n",
      "154 57 77 100 166\n",
      "155 35 77 6 117\n",
      "156 -15 78 21 241\n",
      "157 19 78 466 234\n",
      "158 79 78 6 180\n",
      "159 -30 79 213 158\n",
      "160 -35 79 458 309\n",
      "161 17 79 6 508\n",
      "162 67 80 119 168\n",
      "163 -56 81 437 152\n",
      "164 7 81 21 208\n",
      "165 -28 82 151 199\n",
      "166 -24 82 469 317\n",
      "167 30 82 318 195\n",
      "170 34 83 447 334\n",
      "171 -46 83 445 275\n",
      "172 39 83 250 245\n",
      "173 -61 83 382 325\n",
      "174 19 83 502 307\n",
      "175 47 83 140 234\n",
      "177 -38 84 353 289\n",
      "178 -23 84 50 226\n",
      "179 85 84 82 153\n",
      "180 34 85 472 295\n",
      "181 -57 86 307 296\n",
      "182 16 86 88 219\n",
      "183 -52 86 48 256\n",
      "184 -39 87 39 18\n",
      "185 -81 87 423 253\n",
      "186 26 87 227 269\n",
      "187 82 87 94 260\n",
      "188 -62 87 6 161\n",
      "189 41 87 285 166\n",
      "191 31 88 430 218\n",
      "192 -69 88 472 322\n",
      "193 83 88 79 351\n",
      "194 -44 88 422 341\n",
      "195 -40 88 371 253\n",
      "196 47 88 244 132\n",
      "198 -32 89 23 252\n",
      "199 53 89 290 255\n",
      "200 -35 89 425 281\n",
      "201 49 89 62 180\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
